// UNCLASSIFIED
//-
	Render a skin when DEBE encounters dynamic view endpoints /DS.MODE where
		&mode = MODE = brief | gridbrief | runbrief | pivbrief| run | plugin | view | pivot
		&cols = [key.type.label, ...]
		&page = page size of DS grid
		&refresh = refresh time of associated job grid
		&width = post width
		&height = post height

extends base
append base_parms
	case query.mode
		when "brief"
		when "gridbrief"
		when "runbrief"
		when "pivbrief"
			- tech = "reveal"
		default
			- tech = "extjs"

extends site
append site_parms
	case query.mode
		when "site"
			- view = "Basic"
		when "plugin"
			- view = "Insert"
			- options = { "more+":"", "more++":"", less:"" }
		when "run"
			- view = "Typical"
			- options = { "more+":"", "more++":"", less:"" }
		default
			- view = "Nada"

append site_body

	- mode = query.mode
	- ds = query.ds || "myplugin"
	- pivcol = "tbd"
	- dscols = query.cols || ""
	- dspage = query.page || 20
	- dsrefresh = query.refresh || ""
	- dsdb = `/${ds}.db`
	- dstitle = ds + " view"
	- dsdims = query.dims
	- dims = dsdims.split(",")
	- height = dims.pop()
	- width = dims.pop()
	- tasks = projs ? get( projs , {Plugin:ds}, "Task,Hours,Complete,FAQ1,FAQ2") : []
	- more = parseInt(query.more) || 0

	case mode
		when "plugin"
		when "run"
			#grid.Usecases(
				path=dsdb,
				cols=dscols,
				menu="Agents",
				wrap,
				blogs="Description",
				dims=dsdims,
				hover="finished",
				page=dspage )

				:markdown
					Execute your *#{ds}* plugin from its [run](#{ds}.run), [usecase](#{ds}.view), or 
					[plugin](#{ds}.plugin) view by selecting the desired usecase context and clicking *Execute*.  You 
					may also execute *#{ds}* directly by [usecase Name](/#{ds}.exe?name=CASE) or 
					by [usecase ID](#{ds}.exe?id=CASE).
					
					Its usecase context may include the following optional ( add / remove ) keys:  
					> [+](/#{ds}.add?Export=false) [/-](/#{ds}.sub?Export) *Export* switch writes engine results into a file  
					> [+](/#{ds}.add?Ingest=false) [/-](/#{ds}.sub?Ingest) *Ingest* switch ingests engine results into the database  
					> [+](/#{ds}.add?Share=false) [/-](/#{ds}.sub?Share) *Share* switch returns engine results to the status area  
					> [+](/#{ds}.add?Pipe=doc) [/-](/#{ds}.sub?Pipe) *Pipe* json regulates chips and events to the engine  
					> [+](/#{ds}.add?Description=doc) [/-](/#{ds}.sub?Description) *Description* documents a usecase  
					> [+](/#{ds}.add?Config=doc) [/-](/#{ds}.sub?Config) *Config* js-script defines usecase context  
					> [+](/#{ds}.add?Entry=doc) [/-](/#{ds}.sub?Entry) *Entry* json primes context on entry using { KEY: "SELECT ....", ...}  
					> [+](/#{ds}.add?Exit=doc) [/-](/#{ds}.sub?Exit) *Exit* json saves context on exit using { KEY: "UPDATE ....", ...}  
					> [+](/#{ds}.add?Autorun=doc) [/-](/#{ds}.sub?Autorun) *Autorun* switch enables the autorun watchdog
					> *Save_STATE* aggregates events [ {at:"STATE", ...}, ... ]  
					> *Save_rem* collects remaining unaggregated events  
					> *Save_jpg* generates jpg from {at: "jpg": prime: "name", save: "name", index: [...], values: [...] } event  

					Place a DATASET into a supervised workflow using the *Pipe*:

						"DATASET.TYPE?QUERY"  
						{ "path": "DATASET.TYPE?QUERY", "KEY": [VALUE, ...] , ... "norun": true }

					The {...} pipe generates usecases over the permuted context KEYs.  The "..." pipe selects the workflow based 
					on TYPE = json || jpg || stream || txt || aoi || db using TYPE-specific [QUERY keys](/api.view).
				
						group = "KEY, ..."  
						where = { KEY: VALUE, ...}  
						order = "KEY, ..."  
						limit = NUMBER  
						aoi = "NAME" || [ [lat,lon], ... ]  
						batch = NUMBER  // 0 disables  
						symbols = [ NUMBER, ... ]  
						keys = [ "KEY", ... ]  
						steps = NUMBER   // overrides file defaults  
						actors = NUMBER  // overrides file defaults

					and provide additional context keys:

						Host name of plugin  
						File context during a piped-workflow  
						Voxel context during a piped-workflow  
						Sensor context for current voxel  
						Chip  context with filepath for first jpeg collected in current voxel  
						Flux solar flux at earth's surface for current voxel  
						Events associated with current voxel  
						Flow context of workflow supervisor  
						Stats context shared with all plugins

					where *Flow* contains the supervisors':   
					> *F* where F[k] = frequency of count k  
					> *T*  observation time [1/Hz]  
					> *J* where J[n] = number of jumps taken by n'th process at time T  
					> *N ensemble size  
					> *trP*	 where trP[n,m] = estimated state transition (from,to) probs at time T  
					> *store* event store at time T

					Plugin header colors reflect [status](/projects.view): <font color="green">completed</font>, <font color="blue">policed</font>, <font color="orange">funded</font>, <font color="red">unfunded</font>.
	
			#form.Engine(
				path="/engines.db?Name=#{ds}",
				hover="pending",
				head="select,insert,update,|,delete,|,refresh,login",
				login="/login?pass=",
				cols="ID,Name,Type,Enabled.c,Program(Code.x,State.x.Context,Wrap.x)")

				:markdown
					This engine remains invisible until it has been formally transitioned.

			#grid.Jobs(
				path="/queues.db?Name=#{ds}",
				cols="Arrived.d,Departed.d,Client,Notes.x,QoS.n,Age.n,Funded.c,Finished.c,Priority.n,Work.n,State.n,Task.t,Signoffs(Flagged.c,Sign0.c,Sign1.c,Sign2.c,Sign3.c)",
				wrap,
				head="Print,Refresh,Execute,Help",
				hover="policed",
				page=dspage )

				:markdown
					sorts="Work,State"
					refresh=refresh
					Jobs created by this plugin are show here.  If the job originator exceeded their credits,
					the job is marked "unfunded"; otherwise the job is marked "funded".  If you would like to 
					fund an unfended job, simply click its "(un)funded" link.  To decide if this is a wise purchase, 
					click the "#{ds}" link to see the test case case being explored; additional project information,
					if available, is attached as "RTP", "PMR" etc links.  Earning job credits is easy: simply 
					upload your data using the Files | Uploads.

			#post.ToU(path="/#{ds}.tou",dims="1800,600",wrap)

			#grid.Files(
				path="/files.db",
				wrap,
				cols="Name,Path,Ingest,Classif,PoP_Expires,PoP_Start,PoP_End,PoP_durationDays,PoP_advanceDays" )

			if more>0
				#grid.ContextKeys(
					path="/keyedit.db?ds=#{ds}",
					cols="Key,Type,Samples.x,Dist,Parms.x",
					wrap,
					page=dspage)
					
			if more>1
				#post.Flow( path="/#{ds}_flow.view", dims="1800,600",wrap )

		when "pivot"
			#pivot(
				class=dstitle,
				path=dsdb,
				pivots=pivcol,
				cols=dscols,
				page=dspage )

		when "brief"
		when "gridbrief"
			section
				h3.hd= dstitle

				if query.data
					div!= gridify( query.data )

				else				
					iframe(
						src="/#{ds}.view?dims=#{dsdims}",
						width=width,
						height=height )

		when "pivbrief"
			section
				h3.hd= dstitle
				iframe(
					src="/#{ds}.pivot?dims=#{dsdims}",
					width=width,
					height=height )

		when "runbrief"
			section
				h3.hd= dstitle				
				iframe(
					src="/#{ds}.run?dims=#{dsdims}",
					width=width,
					height=height )

		when "calc"
			#grid(
				class=dstitle,
				path=dsdb,
				calc=1,
				cols="W*10",
				dims=dsdims,
				page=dspage )
				
		default
			#grid(
				class=dstitle,
				path=dsdb,
				cols=dscols,
				dims=dsdims,
				page=dspage )

// UNCLASSIFIED
